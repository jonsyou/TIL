# SMOTE를 통한 데이터 불균형 처리


## 오늘 공부한 것
예전 항공지연예측에 대한 공모전에 참가하여 데이터 불균형에 대해 처음으로 관심있게 찾아본적이 있었다. 그때 당시 ```target``` 변수인 지연 여부에 대한 정보가 불균형한 형태를 가지고 있어서 예측을 위해 언더샘플링, 오버샘플링에 대해 찾아본 기억이 있다. 이를 잘 정리해두면 이후에 이같은 상황을 맞이하였을 때 하나의 대처 방법으로 빠르게 고려해볼 수 있다고 생각한다. 그리하여 오늘은  데이터 불균형을 처리 하기 위한 기법들을 다시 공부해보았다. 


## 개요
데이터 분석을 하다보면 비교적 쉽게 데이터 불균형의 경우를 접할 수 있다. 예를 들면 기업 부도 예측, 혹은 심장병 발생 여부 예측 등의 경우에 ```target``` 변수가 불균형한 경우이다.

이러한 비대칭 데이터의 경우엔 정확도(```accuracy```)가 아무리 높더라도 재현율(```recall```)이 급격히 낮아질 수 있다. 

쉽게 예를 들자면 100명중 3명이 심장병 환자일 때 심장병 환자를 예측하는 경우, 모두 정상이라고 예측해버리면 정확도가 97%가 나온다. 그러나 우리는 심장병 환자를 제대로 예측하여 병이 더 악화되기전에 막고자 하는데에 의의가 있다. 즉, 심장병 환자를 정확히 예측하는 비율인 재현율(```recall```)이 정확도(```accuracy```)보다 중요하다고 할 수 있다. 하지만 비대칭 데이터이다 보니 재현율 낮아질 수 있다. 이에대한 대처로 현존하는 데이터 불균형 처리 기법들을 알아보고자 한다.


## 데이터 불균형 처리 방법
### 언더 샘플링
1. 무작위추출 : 무작위로 정상 데이터 일부만 선택
2. 유의정보 : 유의한 데이터만 남기는 방식

언더 샘플링의 경우 데이터의 소실이 크고, 때로는 중요 정상 데이터를 잃게 될 가능성이 있다.

![image](https://user-images.githubusercontent.com/74973306/114308883-4ee7b980-9b20-11eb-8250-50733f35115a.png)

### 오버 샘플링
1. 무작위추출 : 무작위로 소수 데이터를 복제
2. 유의정보 : 사전 기준을 정해 소수 데이터 복제  
- 정보가 손실되지 않는다는 장점이 있으나, 복제된 관측치를 원래 데이터 세트에 추가하기 만하면 여러 유형의 관측치를 다수 추가하여 오버 피팅(```overfitting```)을 초래할 수 있다. 
- 이러한 경우 ```trainset```의 성능은 높으나 ```testset```의 성능은 나빠질 수 있다.

3. 합성 데이터 생성 : 소수 데이터를 단순 복제하는 것이 아니라 새로운 복제본을 만들어 낸다.
- 딥러닝이나 머신러닝 같이 데이터 확보가 중요한 분석에서는 아무래도 오버샘플링이 많이 행해진다고 한다. 그중에서 ```SMOTE```(Synthetic Minority Over-sampling Technique)가 대표적으로 잘 알려져 있다. 

![image](https://user-images.githubusercontent.com/74973306/114309032-c3225d00-9b20-11eb-823b-556096f97040.png)


## SMOTE 
```SMOTE```는 낮은 비율 클래스 데이터들의 최근접 이웃을 이용하여 새로운 데이터를 생성하는 오버샘플링의 기법이다. ```SMOTE```는 쉽게말하면 아래 그림과 같이 근접 데이터들을 이용해 일정거리 만큼 떨어진 위치에 데이터를 생성하는 기법이다.

![image](https://user-images.githubusercontent.com/74973306/114402454-cda32c00-9bde-11eb-8530-2acffff04e53.png)

### 오버샘플링시 주의할 점
낮은 비율의 클래스 데이터가 증가하면서 재현율과 정밀도가 ```trade-off```되는 경향이 발생한다. 이를 유의해야하며 오버샘플링을 너무 남용해서는 안된다.

## 작성해본 코드
데이터는 현재 참가중인 공모전의 데이터를 활용하여 한번 적용해보았다. 편의상 숫자형 변수만 추출하여 진행하였으며, 만약 범주형 변수가 있다면 ```One-hot encoding```을 진행 후 오버샘플링 하기 바란다.

- ```SMOTE``` 적용 전
```python
import matplotlib.pyplot as plt

from collections import Counter
from sklearn.preprocessing import LabelEncoder

# 데이터 ndarray 형태로 저장
data = train.values

# X,y 데이터셋 분리
X,y = data[:,:-1],data[:,-1]

# 라벨 인코더 적용
y = LabelEncoder().fit_transform(y)

# 클래스별 빈도를 체크하기 위한 코드
counter = Counter(y)
for k,v in counter.items():
  per = v / len(y)*100
  print('Class = %d, n =  %d (%.3f%%)' % (k,v,per))

# 클래스별 빈도 막대그래프
plt.bar(counter.keys(),counter.values())
plt.show()
```
Class = 1, n =  6267 (23.687%)  
Class = 2, n =  16968 (64.134%)  
Class = 0, n =  3222 (12.178%)  
![image](https://user-images.githubusercontent.com/74973306/114406655-acdcd580-9be2-11eb-8960-54e2c5230b66.png)

- ```SMOTE``` 적용 후
```python
import matplotlib.pyplot as plt

from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.preprocessing import LabelEncoder

# 데이터 ndarray 형태로 저장
data = train.values

# X,y 데이터셋 분리
X,y = data[:,:-1],data[:,-1]

# 라벨 인코더 적용
y = LabelEncoder().fit_transform(y)

# SMOTE 기법 적용 
oversample = SMOTE()
X,y = oversample.fit_resample(X,y)

# SMOTE 적용 후 클래스별 빈도 확인
counter = Counter(y)
for k,v in counter.items():
  per = v / len(y)*100
  print('Class = %d, n =  %d (%.3f%%)' % (k,v,per))

# 막대그래프 시각화
plt.bar(counter.keys(),counter.values())
plt.show()
```
Class = 1, n =  16968 (33.333%)  
Class = 2, n =  16968 (33.333%)  
Class = 0, n =  16968 (33.333%)  
![image](https://user-images.githubusercontent.com/74973306/114407071-02b17d80-9be3-11eb-8675-40c70e11a85f.png)

- ```SMOTE``` 기법 적용 (클래스별 오버샘플링 크기 직접 지정)
```python
import matplotlib.pyplot as plt

from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.preprocessing import LabelEncoder

data = train.values

X,y = data[:,:-1],data[:,-1]

y = LabelEncoder().fit_transform(y)

# transform the dataset
strategy = {0:30000, 1:30000, 2:20000}
oversample = SMOTE(sampling_strategy=strategy)
X, y = oversample.fit_resample(X, y)

counter = Counter(y)
for k,v in counter.items():
	per = v / len(y) * 100
	print('Class=%d, n=%d (%.3f%%)' % (k, v, per))
# plot the distribution
plt.bar(counter.keys(), counter.values())
plt.show()
```
Class=1, n=30000 (37.500%)  
Class=2, n=20000 (25.000%)  
Class=0, n=30000 (37.500%)  
![image](https://user-images.githubusercontent.com/74973306/114407271-3096c200-9be3-11eb-8aaa-4520b758564b.png)

## 요약 및 느낀점
오늘은 ```SMOTE```를 이용해 클래스별 샘플을 재표집 하는 과정에 대해 간략하게 알아보았다. ```SMOTE```는 대표적인 오버샘플링 기법이므로 잘 알아두도록 하자. 점점 공부를 하면 할수록 세상에는 다양한 기법들이 많다는 것을 느낀다. 단순히 학습으로 그치지 말고 나도 획기적인 아이디어를 내뱉을 수 있는 그런 사람이 되도록 노력할 것이다.  

> 참고 : https://mkjjo.github.io/python/2019/01/04/smote_duplicate.html
